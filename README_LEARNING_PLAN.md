# Data Engineering Zoomcamp (AWS-Focused) — Learning Plan

## Why I’m Taking This Course (Even Though I’m Not a Beginner)

I am enrolling in the Data Engineering Zoomcamp by DataTalksClub **intentionally and strategically**.

I already work with:
- Python-based data ingestion
- Large CSV datasets
- AWS services (S3, IAM, EC2, Glue, Athena, Redshift)
- Dockerized pipelines
- Real-world data extraction and transformation

However, my goal is **not** to repeat beginner material.

My goal is to use this course as:
- A **structured reference framework**
- A way to **stress-test my existing knowledge**
- A guide to **strengthen my systems thinking**
- A backbone for building a **production-grade AWS data platform**

In short:  
I am not learning *what tools exist* — I am refining *how and why I use them*.

---

## How I Will Approach the Zoomcamp

I will complete the full course content, but **not as a beginner**.

Instead of following tutorials verbatim, I will:

- Translate **all GCP examples to AWS**
- Treat each module as a **design problem**
- Ask production-level questions such as:
  - What breaks at scale?
  - How do I recover from partial failure?
  - How do I make this observable, repeatable, and auditable?
- Extend each concept beyond the minimum required by the course

The Zoomcamp is my **specification**, not my instructor.

---

## My Learning Philosophy for This Course

I will focus on:

### 1. Systems, Not Scripts
I am not interested in one-off scripts.
Every component I build must fit into a larger, end-to-end system.

### 2. Production Thinking
I will design for:
- Idempotency
- Retry safety
- Backfills
- Schema evolution
- Data quality checks
- Cost awareness

### 3. AWS Fluency
This course will help me strengthen:
- AWS-native architecture thinking
- Trade-offs between services
- When *not* to use certain tools

### 4. Depth Over Speed
I am optimizing for **long-term mastery**, not course completion speed.

---

## How I Will Use Each Zoomcamp Module

| Zoomcamp Topic | How I Will Use It |
|---------------|------------------|
| Docker & SQL | As a production runtime and staging layer |
| Ingestion | Hardened, logged, auditable ingestion pipelines |
| Airflow | Orchestration, recovery, and operational control |
| Data Warehouse | Redshift + Athena design trade-offs |
| Spark | Large-scale batch transformations with schema enforcement |
| Terraform | Reproducible AWS infrastructure |
| Data Quality | Detecting silent failures and schema drift |

---

## What Success Looks Like for Me

By the end of this Zoomcamp, I expect to have:

- A **real AWS data engineering capstone**, not a toy project
- A deep understanding of **end-to-end batch analytics systems**
- Clear architectural opinions I can explain and defend
- Production-ready code I can point to
- Meaningful technical insights to share publicly (LinkedIn, GitHub)

---

## Public Learning & Knowledge Sharing

As I progress, I will:
- Share architecture insights (not “I learned X” posts)
- Document failures, trade-offs, and design decisions
- Treat learning as part of my professional identity

This course is not a checkbox.
It is a **tool to sharpen how I already work as a data engineer**.
